{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_expr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use of ðžð±ð©ð«() in #pyspark âœï¸\n",
        "\n",
        "ð„ð±ð©ð«():-\n",
        "====\n",
        "â˜‘ï¸ It is a SQL function in pyspark to ðžð±ðžðœð®ð­ðž ð’ðð‹-ð¥ð¢ð¤ðž ðžð±ð©ð«ðžð¬ð¬ð¢ð¨ð§ð¬.\n",
        "\n",
        "ðŸ”µ ð’ð²ð§ð­ðšð±:- ðžð±ð©ð«(ð¬ð­ð«)\n",
        "\n",
        "â˜‘ï¸ It will take SQL expression as a ð¬ð­ð«ð¢ð§ð  ðšð«ð ð®ð¦ðžð§ð­ and performs the operations within the expression.\n",
        "\n",
        "â˜‘ï¸ It allows using SQL-like functions that are not present in PySpark Column type & pyspark.sql.functions API. Ex:- ð‚ð€ð’ð„ ð–ð‡ð„ð\n",
        "\n",
        "â˜‘ï¸ We are allowed to use ðƒðšð­ðšð…ð«ðšð¦ðž ðœð¨ð¥ð®ð¦ð§ð¬ in the expression.\n",
        "\n",
        "\n",
        "Follow for more:- \n",
        "https://www.linkedin.com/in/kishanyadav/\n",
        "\n",
        "\n",
        "############......  H@@py Learning!!! .......##########"
      ],
      "metadata": {
        "id": "55i2WzI53ceu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyspark in google colab\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "eq0lZ5biTCFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing neccessary libs\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "# creating session\n",
        "spark = SparkSession.builder.appName(\"practice\").getOrCreate()\n",
        "\n",
        "# create dataframe\n",
        "data = [(\"Prashant\",\"Banglore\",25, 58, \"2022-08-01\", 1), (\"Ankit\",\"Banglore\",26, 54, \"2021-05-02\", 2),\n",
        "        (\"Ramakant\",\"Gurugram\",24, 60, \"2022-06-02\", 3), (\"Brijesh\",\"Gazipur\", 26, 75, \"2022-07-04\", 4),\n",
        "        (\"Devendra\",\"Gurugram\", 27, 62, \"2022-04-03\", 5), (\"Ajay\",\"Chandigarh\", 25, 72, \"2022-02-01\", 6)]\n",
        "columns= [\"friends_name\",\"location\", \"age\", \"weight\", \"meetup_date\", \"offset\"]\n",
        "df_friends = spark.createDataFrame(data = data, schema = columns)\n",
        "df_friends.show()\n",
        "\n",
        "# Concatenating One or More Columns\n",
        "# concate friends name, age and location columns uausig expr()\n",
        "df_concat = df_friends.withColumn(\"name-age-location\", expr(\"friends_name|| '-'|| age || '-' || location\"))\n",
        "df_concat.show()\n",
        "\n",
        "# Add a New Column Based on Conditions\n",
        "# check if exercise needed based on weight\n",
        "# if weight is more or equal to 60 -- Yes\n",
        "# if weight is less than 55 -- No\n",
        "# else \"Enjoy\"\n",
        "df_condition = df_friends.withColumn(\"Exercise_Need\", expr(\"CASE WHEN weight >= 60  THEN 'Yes' \" + \"WHEN  weight < 55  THEN 'No' ELSE 'Enjoy' END\"))\n",
        "df_condition.show()\n",
        "\n",
        "# Creating a new column using the existing column value inside the expression\n",
        "# let increment the meetup month by number of offset\n",
        "df_meetup = df_friends.withColumn(\"new_meetup_date\", expr(\"add_months(meetup_date,offset)\"))\n",
        "df_meetup.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pSMJtnR2aJF",
        "outputId": "7624e8c2-df19-4568-c926-5322690ec9d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+---+------+-----------+------+\n",
            "|friends_name|  location|age|weight|meetup_date|offset|\n",
            "+------------+----------+---+------+-----------+------+\n",
            "|    Prashant|  Banglore| 25|    58| 2022-08-01|     1|\n",
            "|       Ankit|  Banglore| 26|    54| 2021-05-02|     2|\n",
            "|    Ramakant|  Gurugram| 24|    60| 2022-06-02|     3|\n",
            "|     Brijesh|   Gazipur| 26|    75| 2022-07-04|     4|\n",
            "|    Devendra|  Gurugram| 27|    62| 2022-04-03|     5|\n",
            "|        Ajay|Chandigarh| 25|    72| 2022-02-01|     6|\n",
            "+------------+----------+---+------+-----------+------+\n",
            "\n",
            "+------------+----------+---+------+-----------+------+--------------------+\n",
            "|friends_name|  location|age|weight|meetup_date|offset|   name-age-location|\n",
            "+------------+----------+---+------+-----------+------+--------------------+\n",
            "|    Prashant|  Banglore| 25|    58| 2022-08-01|     1|Prashant-25-Banglore|\n",
            "|       Ankit|  Banglore| 26|    54| 2021-05-02|     2|   Ankit-26-Banglore|\n",
            "|    Ramakant|  Gurugram| 24|    60| 2022-06-02|     3|Ramakant-24-Gurugram|\n",
            "|     Brijesh|   Gazipur| 26|    75| 2022-07-04|     4|  Brijesh-26-Gazipur|\n",
            "|    Devendra|  Gurugram| 27|    62| 2022-04-03|     5|Devendra-27-Gurugram|\n",
            "|        Ajay|Chandigarh| 25|    72| 2022-02-01|     6|  Ajay-25-Chandigarh|\n",
            "+------------+----------+---+------+-----------+------+--------------------+\n",
            "\n",
            "+------------+----------+---+------+-----------+------+-------------+\n",
            "|friends_name|  location|age|weight|meetup_date|offset|Exercise_Need|\n",
            "+------------+----------+---+------+-----------+------+-------------+\n",
            "|    Prashant|  Banglore| 25|    58| 2022-08-01|     1|        Enjoy|\n",
            "|       Ankit|  Banglore| 26|    54| 2021-05-02|     2|           No|\n",
            "|    Ramakant|  Gurugram| 24|    60| 2022-06-02|     3|          Yes|\n",
            "|     Brijesh|   Gazipur| 26|    75| 2022-07-04|     4|          Yes|\n",
            "|    Devendra|  Gurugram| 27|    62| 2022-04-03|     5|          Yes|\n",
            "|        Ajay|Chandigarh| 25|    72| 2022-02-01|     6|          Yes|\n",
            "+------------+----------+---+------+-----------+------+-------------+\n",
            "\n",
            "+------------+----------+---+------+-----------+------+---------------+\n",
            "|friends_name|  location|age|weight|meetup_date|offset|new_meetup_date|\n",
            "+------------+----------+---+------+-----------+------+---------------+\n",
            "|    Prashant|  Banglore| 25|    58| 2022-08-01|     1|     2022-09-01|\n",
            "|       Ankit|  Banglore| 26|    54| 2021-05-02|     2|     2021-07-02|\n",
            "|    Ramakant|  Gurugram| 24|    60| 2022-06-02|     3|     2022-09-02|\n",
            "|     Brijesh|   Gazipur| 26|    75| 2022-07-04|     4|     2022-11-04|\n",
            "|    Devendra|  Gurugram| 27|    62| 2022-04-03|     5|     2022-09-03|\n",
            "|        Ajay|Chandigarh| 25|    72| 2022-02-01|     6|     2022-08-01|\n",
            "+------------+----------+---+------+-----------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}